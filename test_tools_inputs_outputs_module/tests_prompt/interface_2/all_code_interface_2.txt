Assume you are an experienced tester. I am going to give you python functions and you are going to give me the inputs to test this function. The inputs are provided in the form of actions. You have to provide three tests for each function within the same file with the most number of parameters as possible (if applicable). However, you have to follow the format that I provide to you below.

# Format:
{
    "env": "wiki_pages",
    "interface_num": 2,
    "task": {
        "actions": [
            {
                "name": "discover_user_entities",
                "arguments": {
                    "entity_type": "users",
                    "filters": {
                        "email": "sarahcampos144@hotmail.com"
                    }
                }
            },
            {
                "name": "discover_user_entities",
                "arguments": {
                    "entity_type": "users",
                    "filters": {
                        "email": "sarahcampos144@hotmail.com"
                    }
                }
            }
        ]
    }
}

where the name of action is the function name and the arguments are the parameters of the function. You have to provide multiple actions for a single file in a single test if applicable. 

# Functions:
import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool



class ObtainUser(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        user_id: Optional[str] = None,
        email: Optional[str] = None,
        status: Optional[str] = None,
    ) -> str:
        """
        Obtain user details from the Confluence database (SharePoint 'obtain_user' logic).
        Maps SharePoint user queries to Confluence users table.
        """
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        users = data.get("users", {})
        results = []
        
        for uid, user_data in users.items():
            match = True
            
            if user_id and uid != user_id:
                match = False
            if email and user_data.get("email") != email:
                match = False
            if status and user_data.get("status") != status:
                match = False
            
            if match:
                results.append({
                    "user_id": uid,
                    "email": user_data.get("email"),
                    "display_name": user_data.get("display_name"),
                    "status": user_data.get("status"),
                    "created_at": user_data.get("created_at"),
                    "updated_at": user_data.get("updated_at")
                })
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "users": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "obtain_user",
                "description": "Obtain user details. Filters by user_id, email, or status ('active', 'inactive', 'deactivated'). Returns user information including user_id, email, display_name, status, created_at, and updated_at.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "user_id": {
                            "type": "string",
                            "description": "Unique user identifier"
                        },
                        "email": {
                            "type": "string",
                            "description": "User email address"
                        },
                        "status": {
                            "type": "string",
                            "description": "User status: 'active', 'inactive', 'deactivated'",
                            "enum": ["active", "inactive", "deactivated"]
                        }
                    },
                    "required": []
                }
            }
        }

# -----------------

ALL_TOOLS_INTERFACE_2 = []


# -----------------

import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class AddPage(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        title: str,
        site_id: str,
        created_by: str,
        parent_page_id: Optional[str] = None,
        body_storage: Optional[str] = None,
        status: Optional[str] = None,
    ) -> str:
        """
        Add a new page in the Confluence database (SharePoint 'add_page' logic).
        Maps SharePoint page creation to Confluence pages (site_id maps to space_id).
        """
        def generate_id(table: Dict[str, Any]) -> str:
            if not table:
                return "1"
            return str(max(int(k) for k in table.keys()) + 1)
        
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        pages = data.get("pages", {})
        spaces = data.get("spaces", {})
        users = data.get("users", {})
        
        # Validate required fields
        if not all([title, site_id, created_by]):
            return json.dumps({
                "success": False,
                "error": "Missing required parameters: title, site_id, created_by"
            })
        
        # Validate site exists
        if site_id not in spaces:
            return json.dumps({
                "success": False,
                "error": f"Site with ID '{site_id}' not found"
            })
        
        # Validate user exists
        if created_by not in users:
            return json.dumps({
                "success": False,
                "error": f"User with ID '{created_by}' not found"
            })
        
        # Validate parent page if provided
        if parent_page_id and parent_page_id not in pages:
            return json.dumps({
                "success": False,
                "error": f"Parent page with ID '{parent_page_id}' not found"
            })
        
        # Check for duplicate title in the same site
        for page_data in pages.values():
            if page_data.get("space_id") == site_id and page_data.get("title") == title:
                return json.dumps({
                    "success": False,
                    "error": f"Page with title '{title}' already exists in this site"
                })
        
        # Generate new page ID
        new_page_id = generate_id(pages)
        timestamp = "2025-10-01T00:00:00"
        
        # Create new page record
        new_page = {
            "page_id": new_page_id,
            "title": title,
            "space_id": site_id,
            "parent_page_id": parent_page_id,
            "body_storage": body_storage,
            "status": status if status else "current",
            "created_by": created_by,
            "created_at": timestamp,
            "updated_by": created_by,
            "updated_at": timestamp
        }
        
        pages[new_page_id] = new_page
        
        return json.dumps({
            "success": True,
            "page_id": new_page_id,
            "title": title,
            "site_id": site_id,
            "parent_page_id": parent_page_id,
            "body_storage": body_storage,
            "status": new_page["status"],
            "created_by": created_by,
            "created_at": timestamp,
            "updated_by": created_by,
            "updated_at": timestamp
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "add_page",
                "description": "Add a new page. Requires title, site_id, and created_by. Optional: parent_page_id (for child pages), body_storage (page content), status ('current', 'draft', 'locked', 'archived', 'deleted', defaults to 'current'). Returns created page details including page_id, title, site_id, parent_page_id, body_storage, status, created_by, created_at, updated_by, and updated_at.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "title": {
                            "type": "string",
                            "description": "Page title (must be unique within the site)"
                        },
                        "site_id": {
                            "type": "string",
                            "description": "Site (space) identifier where the page will be created"
                        },
                        "created_by": {
                            "type": "string",
                            "description": "User ID creating the page"
                        },
                        "parent_page_id": {
                            "type": "string",
                            "description": "Parent page identifier for creating a child page"
                        },
                        "body_storage": {
                            "type": "string",
                            "description": "Page content in storage format"
                        },
                        "status": {
                            "type": "string",
                            "description": "Page status: 'current', 'draft', 'locked', 'archived', 'deleted' (defaults to 'current')",
                            "enum": ["current", "draft", "locked", "archived", "deleted"]
                        }
                    },
                    "required": ["title", "site_id", "created_by"]
                }
            }
        }


# -----------------

import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool


class DiscoverPage(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        page_id: Optional[str] = None,
        title: Optional[str] = None,
        site_id: Optional[str] = None,
        parent_page_id: Optional[str] = None,
        status: Optional[str] = None,
        created_by: Optional[str] = None,
        created_at: Optional[str] = None,
        updated_by: Optional[str] = None,
        updated_at: Optional[str] = None,
    ) -> str:
        """
        Discover page details from the Confluence database (SharePoint 'discover_page' logic).
        Maps SharePoint pages to Confluence pages (site_id maps to space_id).
        """
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        pages = data.get("pages", {})
        results = []
        
        for pid, page_data in pages.items():
            match = True
            
            if page_id and pid != page_id:
                match = False
            if title and page_data.get("title") != title:
                match = False
            if site_id and page_data.get("space_id") != site_id:
                match = False
            if parent_page_id and page_data.get("parent_page_id") != parent_page_id:
                match = False
            if status and page_data.get("status") != status:
                match = False
            if created_by and page_data.get("created_by") != created_by:
                match = False
            if created_at and page_data.get("created_at") != created_at:
                match = False
            if updated_by and page_data.get("updated_by") != updated_by:
                match = False
            if updated_at and page_data.get("updated_at") != updated_at:
                match = False
            
            if match:
                results.append({
                    "page_id": pid,
                    "title": page_data.get("title"),
                    "site_id": page_data.get("space_id"),
                    "parent_page_id": page_data.get("parent_page_id"),
                    "body_storage": page_data.get("body_storage"),
                    "status": page_data.get("status"),
                    "created_by": page_data.get("created_by"),
                    "created_at": page_data.get("created_at"),
                    "updated_by": page_data.get("updated_by"),
                    "updated_at": page_data.get("updated_at")
                })
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "pages": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "discover_page", # RENAMED from get_page
                "description": "Discover page details. Filters by page_id, title, site_id, parent_page_id, status ('current', 'draft', 'locked', 'archived', 'deleted'), created_by, created_at, updated_by, or updated_at. Date format: YYYY-MM-DDTHH:MM:SS. Returns page information including page_id, title, site_id, parent_page_id, body_storage, status, created_by, created_at, updated_by, and updated_at.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "page_id": {
                            "type": "string",
                            "description": "Unique page identifier"
                        },
                        "title": {
                            "type": "string",
                            "description": "Page title"
                        },
                        "site_id": {
                            "type": "string",
                            "description": "Site (space) identifier where the page resides"
                        },
                        "parent_page_id": {
                            "type": "string",
                            "description": "Parent page identifier for child pages"
                        },
                        "status": {
                            "type": "string",
                            "description": "Page status: 'current', 'draft', 'locked', 'archived', 'deleted'",
                            "enum": ["current", "draft", "locked", "archived", "deleted"]
                        },
                        "created_by": {
                            "type": "string",
                            "description": "User ID who created the page"
                        },
                        "created_at": {
                            "type": "string",
                            "description": "Page creation timestamp (YYYY-MM-DDTHH:MM:SS)"
                        },
                        "updated_by": {
                            "type": "string",
                            "description": "User ID who last updated the page"
                        },
                        "updated_at": {
                            "type": "string",
                            "description": "Page last update timestamp (YYYY-MM-DDTHH:MM:SS)"
                        }
                    },
                    "required": []
                }
            }
        }


# -----------------

import json
from typing import Any, Dict, Optional
from tau_bench.envs.tool import Tool



class SearchSite(Tool):
    @staticmethod
    def invoke(
        data: Dict[str, Any],
        site_id: Optional[str] = None,
        site_url: Optional[str] = None,
        site_name: Optional[str] = None,
        description: Optional[str] = None,
        status: Optional[str] = None,
        created_by: Optional[str] = None,
        created_at: Optional[str] = None,
        updated_at: Optional[str] = None,
    ) -> str:
        """
        Search for site details from the Confluence database (SharePoint 'search_site' logic).
        Maps SharePoint sites to Confluence spaces (site_url maps to space_key, site_name to name).
        """
        if not isinstance(data, dict):
            return json.dumps({
                "success": False,
                "error": "Invalid data format"
            })
        
        spaces = data.get("spaces", {})
        results = []
        
        for sid, space_data in spaces.items():
            match = True
            
            if site_id and sid != site_id:
                match = False
            if site_url and space_data.get("space_key") != site_url:
                match = False
            if site_name and space_data.get("name") != site_name:
                match = False
            if description and space_data.get("description") != description:
                match = False
            if status and space_data.get("status") != status:
                match = False
            if created_by and space_data.get("created_by") != created_by:
                match = False
            if created_at and space_data.get("created_at") != created_at:
                match = False
            if updated_at and space_data.get("updated_at") != updated_at:
                match = False
            
            if match:
                results.append({
                    "site_id": sid,
                    "site_url": space_data.get("space_key"),
                    "site_name": space_data.get("name"),
                    "description": space_data.get("description"),
                    "type": space_data.get("type"),
                    "status": space_data.get("status"),
                    "created_by": space_data.get("created_by"),
                    "created_at": space_data.get("created_at"),
                    "updated_at": space_data.get("updated_at")
                })
        
        return json.dumps({
            "success": True,
            "count": len(results),
            "sites": results
        })
    
    @staticmethod
    def get_info() -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "search_site", # RENAMED from get_site
                "description": "Search for site details. Filters by site_id, site_url, site_name, description, status ('current', 'archived'), created_by, created_at, or updated_at. Date format: YYYY-MM-DDTHH:MM:SS. Returns site information including site_id, site_url, site_name, description, type, status, created_by, created_at, and updated_at.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "site_id": {
                            "type": "string",
                            "description": "Unique site identifier"
                        },
                        "site_url": {
                            "type": "string",
                            "description": "Site URL key"
                        },
                        "site_name": {
                            "type": "string",
                            "description": "Site display name"
                        },
                        "description": {
                            "type": "string",
                            "description": "Site description"
                        },
                        "status": {
                            "type": "string",
                            "description": "Site status: 'current', 'archived'",
                            "enum": ["current", "archived"]
                        },
                        "created_by": {
                            "type": "string",
                            "description": "User ID who created the site"
                        },
                        "created_at": {
                            "type": "string",
                            "description": "Site creation timestamp (YYYY-MM-DDTHH:MM:SS)"
                        },
                        "updated_at": {
                            "type": "string",
                            "description": "Site last update timestamp (YYYY-MM-DDTHH:MM:SS)"
                        }
                    },
                    "required": []
                }
            }
        }


# Policy:
SharePoint Wiki Management Policy
As a Wiki Management Agent, you are responsible for executing Site-level and Page-level management processes, including page lifecycle management, permissions, and components.
General Operating Principles
You must not provide any information, knowledge, procedures, subjective recommendations, or comments that are not supplied by the user or available through tools.
You must deny user requests that violate this policy.
All Standard Operating Procedures (SOPs) are designed for single-turn execution. Each procedure is self-contained and must be completed in one interaction. Each SOP provides clear steps for proceeding when conditions are met and explicit halt instructions with error reporting when conditions are not met.


Permission Structure
Admin permissions encompass all other permissions. Users with “admin” automatically have “create”, “edit”, “view”, “delete”, and all required permission levels for the given entity.
User permissions on pages include both direct permissions and inherited permissions from the hosting Site Pages library or Site. (pages inherit permissions from the Site unless unique permissions are explicitly applied at the page level)


Critical Halt & Transfer Conditions
You must halt the procedure and immediately initiate a switch_to_human if:

The user is unauthorized, lacks required permissions, or is not active.
Missing or invalid credentials are provided.
Any required entity lookup (discover_page, search_site, etc.) fails or the entity is not found.
A failure occurs during the SOP that prevents fulfillment.
Any external integration fails.

Only when none of these conditions occur you proceed to complete the SOP.


Standard Operating Procedures (SOPs)
1. Create Page
Steps:
Retrieve the user details and verify the user exists and has “active” status using obtain_user.
If creating page within a site:
Get the target site or subsite using search_site.
Verify the user from step 1 has “create”, “edit” or “admin” permission on the target site or subsite from step 2.1 using fetch_effective_permissions.
Create the new page using add_page.
2. Update Page
Steps:
Retrieve the user details and verify the user exists and with “active” status using obtain_user.
Retrieve the target page details using discover_page.
Verify that the user from step 1 has “edit” or “admin” permission on the target page from step 2 using fetch_effective_permissions.
If moving the page to a different site or subsite:
Retrieve the target site using search_site.
Verify that the user from step 1 has “view” or “admin” permission on the target site from step 4.1 using fetch_effective_permissions.
Verify the target page from step 2 remains unique within the target site from step 4.1 using get_pages.
Update the target page from step 2 using amend_page.
If updating the page title:
Verify the title remains unique within the site using discover_page.
Apply the update to the page from step 2 using amend_page.
3. Remove Page
Steps:
Retrieve the user details and verify the user exists and with “active” status using obtain_user.
Retrieve the target page using discover_page.
Verify the user from step 2 has “delete” or “admin” permission on the target page from step 1 using fetch_effective_permissions.
Delete the target page from step 1 using remove_page.
4. Modify Page Permissions
Steps:
Retrieve both the acting user and the target user and confirm they have “active” status using obtain_user.
Retrieve the target page and confirm it exists using discover_page.
Retrieve the host site for the target page in step 1 using search_site.
Verify that the acting user from step 1 has “admin” permission on the target page from step 2 or host site from step 3 using fetch_effective_permissions.
Modify the page permissions of the target page from step 1 using set_permission.
5. Create Whiteboard
Steps:
Retrieve the hosting Site or page using search_site or discover_page.
Retrieve the user details and verify the user exists and is “active” using obtain_user.
Verify the user from step 2 has permission to create Whiteboards using fetch_effective_permissions.
Create the whiteboard using new_whiteboard.
6. Update Whiteboard
Steps:
Retrieve the Whiteboard and confirm it exists using get_whiteboard.
Retrieve the hosting Site or Page where the Whiteboard from step 1 is located using search_site or discover_page.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 3 has permission to edit the Whiteboard using fetch_effective_permissions.
Update the Whiteboard from step 1 using edit_whiteboard.
7. Remove Whiteboard
Steps:
Retrieve the Whiteboard and confirm it exists using get_whiteboard.
Retrieve the hosting Site or Page where the Whiteboard from step 1 exists using search_site or discover_page.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 2 has permission to delete the Whiteboard using fetch_effective_permissions.
Delete the Whiteboard from step 1 using remove_whiteboard.
8. Create Quick Link
Steps:
Retrieve the hosting page where the Quick Link will be created using discover_page.
Identify the type of link being added, such as url, page, document, or list item.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 3 has permission to edit the page using fetch_effective_permissions.
Create the new Quick Links Webpart using create_quick_links.
9. Remove Quick Link
Steps:
Retrieve the hosting page that contains the Smart Link using discover_page.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 2 has permission to edit the hosting page using fetch_effective_permissions.
Retrieve the Quick Links Webpart configuration on the hosting page from step 1 using discover_page (page JSON).
Remove the Smart Link by deleting or updating the associated Quick Links Webpart from step 4 using delete_quick_links.
Apply the update to the hosting page from step 1 using amend_page.
10. Update Quick Link
Steps:
Retrieve the hosting page that contains the Smart Link using discover_page.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 2 has permission to edit the hosting page using fetch_effective_permissions.
Retrieve the Quick Links Webpart configuration that includes the Smart Link on the hosting page from step 1 using discover_page.
Update the Smart Link by modifying the corresponding Quick Links Webpart using update_quick_links.
Apply the update to the hosting page from step 1 using amend_page.
11. Create Database
Steps:
Retrieve the target Site where the database will be created using search_site.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 3 has permission to create databases on the target Site using fetch_effective_permissions.
Create the new List using produce_list.
If unique permissions are required for the new List, grant permissions using set_permission.
12. Remove Database
Steps:
Retrieve the hosting Site and confirm it exists using search_site.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 2 has permission to delete the list using fetch_effective_permissions.
Retrieve the list that must be removed using get_list.
Identify all pages that reference the list from step 4 by scanning page webparts using get_pages and inspecting each page’s webpart configuration via discover_page.
For each page containing a List Webpart that references the list from step 4, remove or update the Webpart using delete_list_webpart or adjust_list_webpart.
Delete the list using delete_list.
13. Update Database
Steps:
Retrieve the hosting Site using search_site.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 2 has permission to edit the database list using fetch_effective_permissions.
Retrieve the target list to be updated using get_list.
Update the list settings from step 4 using adjust_list.
14. Add Attachment/Label
Steps:
Retrieve the hosting page and confirm that the page exists using discover_page.
Retrieve the user details and verify the user exists with “active” status using obtain_user.
Verify the user from step 2 has “edit” permission on the page using fetch_effective_permissions.
To add:
an attachment, attach the file using establish_attachment.
a label, update the page’s metadata field from step 1 using create_metadata_field_value.
15. Remove Attachment/Label
Steps:
Retrieve the hosting page and confirm that the page exists using discover_page.
Retrieve the user details and verify the user exists and is active using obtain_user.
Verify the user from step 2 has “edit” permission on the page using fetch_effective_permissions.
To remove:
an attachment, delete it using delete_attachment.
a label, clear or update the page metadata field from step 1 containing the label using create_metadata_field_value or delete_metadata_field_value.
16. Update Attachment/Label
Steps:
Retrieve the hosting page and confirm that the page exists using discover_page.
Retrieve the user details and verify the user exists and is active using obtain_user.
Verify the user from step 2 has “edit” permission on the page using fetch_effective_permissions.
 To update:
an attachment, replace it by deleting the existing attachment using delete_attachment and re-attach with establish_attachment.
a label, modify the associated page metadata field from step 1 using create_metadata_field_value.


# Database Schema:
// DBML Schema for Confluence Content Management System
// Based on actual Confluence database table structure

// ============================================================================
// CORE CONTENT TYPES
// ============================================================================

Table pages {
  page_id varchar(50) [primary key]
  // page_number varchar(50) [not null, unique] // e.g., PAGE0000001
  title varchar(500) [not null]
  space_id varchar(50) [not null]
  parent_page_id varchar(50) // nullable for root pages
  body_storage text // 
  // body_view text // rendered HTML
  status enum('current','draft','locked', 'archived','deleted') [not null, default: 'current']
  // version_number int [not null, default: 1]
  created_by varchar(50) [not null]
  created_at timestamp [not null, default: `NOW()`]
  updated_by varchar(50) [not null]
  updated_at timestamp [not null, default: `NOW()`]

  indexes {
    parent_page_id
    space_id
    // folder_id
    (space_id, status)
    // page_number [unique]
  }
}

Table databases {
  database_id varchar(50) [primary key]
  title varchar(500) [not null]
  host_space_id varchar(50)      // For space-level databases
  host_page_id varchar(50)       // For page-level databases
  // Either host_space_id OR host_page_id must be set (mutually exclusive)
  description text
  status enum('current','archived','deleted') [not null, default: 'current']
  created_by varchar(50) [not null]
  created_at timestamp [not null, default: `NOW()`]
  updated_by varchar(50) [not null]
  updated_at timestamp [not null, default: `NOW()`]
  
  indexes {
    host_space_id
    host_page_id
  }
}

Table whiteboards {
  whiteboard_id varchar(50) [primary key]
  title varchar(500) [not null]
  host_space_id varchar(50)      // For space-level whiteboards
  host_page_id varchar(50)       // For page-level whiteboards  
  content text
  status enum('current','archived','deleted', 'locked') [not null, default: 'current']
  created_by varchar(50) [not null]
  created_at timestamp [not null, default: `NOW()`]
  updated_by varchar(50) [not null]
  updated_at timestamp [not null, default: `NOW()`]
  
  indexes {
    host_space_id
    host_page_id
  }
}

Table smart_links {
  smart_link_id varchar(50) [primary key]
  title varchar(500) [not null]
  url varchar(2000) [not null]
  
  // What this smart link POINTS TO (the reference/target)
  target_id varchar(50)           // The entity this link references
  target_type enum('page','database','whiteboard','external', 'attachment')
  
  // Where this smart link is DISPLAYED (the container)
  host_page_id varchar(50) [not null]
  // host_id varchar(50) [not null]
  // host_type enum('page','database','whiteboard') [not null]
  
  // link_type varchar(100) // e.g., 'jira_issue', 'external_url', etc.
  // link_type enum(
  //   'internal_link',
  //   'document_link',
  //   'repository_link',
  //   'communication_link',
  //   'media_link',
  //   'external_url'
  // ) [not null, default: 'external_url']
  // status enum('current','archived','deleted') [not null, default: 'current']
  created_by varchar(50) [not null]
  created_at timestamp [not null, default: `NOW()`]
  updated_by varchar(50) [not null]
  updated_at timestamp [not null, default: `NOW()`]
  
  indexes {
    // parent_id
    // space_id
    url
  }
}


// ============================================================================
// SPACES
// ============================================================================

Table spaces {
  space_id varchar(50) [primary key]
  space_key varchar(50) [not null, unique]
  name varchar(255) [not null]
  description text
  type enum('global','personal') [not null]
  status enum('current','archived') [not null, default: 'current']
  // homepage_id varchar(50) // FK to pages
  created_by varchar(50) [not null]
  created_at timestamp [not null, default: `NOW()`]
  updated_at timestamp [not null, default: `NOW()`]
  
  indexes {
    space_key [unique]
  }
}

// ============================================================================
// USERS AND AUTHENTICATION
// ============================================================================

Table users {
  user_id varchar(50) [primary key]
  // account_id varchar(100) [not null, unique] // Atlassian account ID
  email varchar(320) [not null, unique]
  display_name varchar(255) [not null]
  // account_type enum('atlassian','app','anonymous') [not null]
  status enum('active','inactive','deactivated') [not null, default: 'active']
  created_at timestamp [not null, default: `NOW()`]
  updated_at timestamp [not null, default: `NOW()`]
  
  indexes {
    // account_id [unique]
    email [unique]
  }
}


// ============================================================================
// ATTACHMENTS
// ============================================================================

Table attachments {
  attachment_id varchar(50) [primary key]
  content_id varchar(50) [not null]
  content_type enum('page','database','whiteboard','smart_link') [not null]
  host_page_id varchar(50) 
  file_name varchar(500) [not null]
  file_url varchar(2000) [not null]
  // file_size_bytes bigint [not null]
  // media_type varchar(100) [not null] // MIME type
  // download_url varchar(2000) [not null]
  // comment text
  // version_number int [not null, default: 1]
  status enum('current','archived','deleted') [not null, default: 'current']
  uploaded_by varchar(50) [not null]
  uploaded_at timestamp [not null, default: `NOW()`]
  updated_at timestamp [not null, default: `NOW()`]
  
  indexes {
    content_id
    (content_id, content_type)
    uploaded_by
  }
}


// ============================================================================
// VERSIONS
// ============================================================================


Table page_versions {
  page_version_id varchar(50) [primary key]
  page_id varchar(50) [not null]
  version_number int [not null]
  title varchar(500) [not null]
  body_storage text
  // is_minor_edit boolean [not null, default: false]
  // created_by varchar(50)  
  created_at timestamp [not null, default: `NOW()`]
}

Table page_version_components {
  component_id varchar(50) [primary key]
  page_version_id varchar(50) [not null]
  component_type enum('whiteboard','smart_link') [not null]
  component_data text [not null] // Complete snapshot of the component
  
  indexes {
    page_version_id
  }
}

Ref: page_version_components.page_version_id > page_versions.page_version_id


// Table whiteboard_versions {
//   whiteboard_version_id varchar(50) [primary key]
//   whiteboard_id varchar(50) [not null]
//   version_number int [not null]
//   title varchar(500) [not null]
//   content text
//   version_message text
//   created_by varchar(50) [not null]
//   created_at timestamp [not null, default: `NOW()`]
  
//   indexes {
//     whiteboard_id
//     (whiteboard_id, version_number) [unique]
//   }
// }



// ============================================================================
// LABELS
// ============================================================================

Table page_labels {
  page_label_id varchar(50) [primary key]
  page_id varchar(50) [not null]
  label_name varchar(255) [not null]  // stored directly
  added_by varchar(50) [not null]
  added_at timestamp [not null, default: `NOW()`]
  
  indexes {
    page_id
    (page_id, label_name) [unique]
  }
}

// Table labels {
//   label_id varchar(50) [primary key]
//   label_name varchar(255) [not null, unique]
//   // prefix varchar(50) // e.g., 'global', 'my', 'team'
//   created_at timestamp [not null, default: `NOW()`]
  
//   indexes {
//     label_name
//   }
// }

// Table page_labels {
//   page_label_id varchar(50) [primary key]
//   page_id varchar(50) [not null]
//   label_id varchar(50) [not null]
//   added_by varchar(50) [not null]
//   added_at timestamp [not null, default: `NOW()`]
  
//   indexes {
//     (page_id, label_id) [unique]
//     label_id
//   }
// }

// Table attachment_labels {
//   attachment_label_id varchar(50) [primary key]
//   attachment_id varchar(50) [not null]
//   label_id varchar(50) [not null]
//   added_by varchar(50) [not null]
//   added_at timestamp [not null, default: `NOW()`]
  
//   indexes {
//     (attachment_id, label_id) [unique]
//     label_id
//   }
// }

// ============================================================================
// LIKES
// ============================================================================

// Table likes {
//   like_id varchar(50) [primary key]
//   page_id varchar(50) [not null]
//   // content_id varchar(50) [not null]
//   // content_type enum('page','database','whiteboard','smart_link') [not null]
//   user_id varchar(50) [not null]
//   // account_id varchar(100) [not null] // Atlassian account ID
//   liked_at timestamp [not null, default: `NOW()`]
  
//   indexes {
//     // (content_id, content_type, user_id) [unique]
//     // content_id
//     user_id
//   }
// }

// ============================================================================
// PERMISSIONS
// ============================================================================

Table permissions {
  permission_id varchar(50) [primary key]
  content_id varchar(50) [not null]
  content_type enum('space','page') [not null]
  user_id varchar(50)
  operation enum('view','edit','delete','create','admin', 'restrict_other_users') [not null]
  granted_by varchar(50)
  granted_at timestamp [not null, default: `NOW()`]
  
  indexes {
    (content_id, content_type)
    user_id
    operation
  }
}


// ============================================================================
// RELATIONSHIPS
// ============================================================================

// Content Pages
Ref: pages.parent_page_id > pages.page_id
Ref: pages.space_id > spaces.space_id
Ref: pages.created_by > users.user_id
Ref: pages.updated_by > users.user_id

// Databases
Ref: databases.host_space_id > spaces.space_id
Ref: databases.host_page_id > pages.page_id
Ref: databases.created_by > users.user_id
Ref: databases.updated_by > users.user_id

// Whiteboards
Ref: whiteboards.host_space_id > spaces.space_id
Ref: whiteboards.host_page_id > pages.page_id
Ref: whiteboards.created_by > users.user_id
Ref: whiteboards.updated_by > users.user_id

// Smart Links
// Ref: smart_links.space_id > spaces.space_id
Ref: smart_links.created_by > users.user_id
Ref: smart_links.updated_by > users.user_id

// Spaces
// Ref: spaces.homepage_id > pages.page_id
Ref: spaces.created_by > users.user_id

// Attachments
Ref: attachments.uploaded_by > users.user_id
// Ref: attachment_bodies.attachment_version_id > attachment_versions.attachment_version_id

// Versions
Ref: page_versions.page_id > pages.page_id
// Ref: page_versions.created_by > users.user_id

// Labels
Ref: page_labels.page_id > pages.page_id
// Ref: page_labels.label_id > labels.label_id
Ref: page_labels.added_by > users.user_id

// Ref: attachment_labels.attachment_id > attachments.attachment_id
// Ref: attachment_labels.label_id > labels.label_id
// Ref: attachment_labels.added_by > users.user_id


// Likes
// Ref: likes.user_id > users.user_id

// Permissions
Ref: permissions.user_id > users.user_id
// Ref: permissions.group_id > groups.group_id
Ref: permissions.granted_by > users.user_id

Ref: smart_links.host_page_id > pages.page_id


You have to provide the json file for each function separately including all the tests for that function in the actions part. You are going to provide the bash script that will create and populate those json files in a folder named tools_regression_tests/interface_2/.

Note: ids are just numeric strings "1", "2", ...
